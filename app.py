import streamlit as st
from core.file_operations import extract_pdfs_into_list
from core.image_similarity import ImageProcessor
from core.text_similarity import TextProcessor
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from core.image_concatenating_similarity import ImageProcessor_Concatenated
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import time  # Import time module

def format_time(seconds):
    """Convert seconds into a human-readable string (HH:MM:SS)."""
    hours, remainder = divmod(seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    return f"{int(hours)}h {int(minutes)}m {int(seconds)}s" if hours > 0 else (
        f"{int(minutes)}m {int(seconds)}s" if minutes > 0 else f"{int(seconds)}s"
    )

# Initialize processors
text_processor = TextProcessor()
image_processor = ImageProcessor()
image_processor_concatenated = ImageProcessor_Concatenated(saturation_threshold=5)
# Page Title
st.title("PDF Similarity Checker")
st.sidebar.title("Options")

# Tooltip section for methods
st.sidebar.markdown("""
<style>
.tooltip {
    position: relative;
    display: inline-block;
    cursor: pointer;
    color: #0073e6;
    font-weight: bold;
    margin-left: 5px;
}
.tooltip .tooltiptext {
    visibility: hidden;
    width: 250px;
    background-color: #555;
    color: #fff;
    text-align: center;
    border-radius: 5px;
    padding: 5px 10px;
    position: absolute;
    z-index: 1;
    bottom: 125%;
    left: 50%;
    margin-left: -125px;
    opacity: 0;
    transition: opacity 0.3s;
}
.tooltip:hover .tooltiptext {
    visibility: visible;
    opacity: 1;
}
</style>

<div>
    <p>Methods:</p>
    <ul>
        <li>Individual Image <span class="tooltip">❓
            <span class="tooltiptext">Compares all the images in one PDF with another PDF using the Difference Comparison method. Calculates the average of the top 10 similarity scores for each pair of images across all PDF comparisons.</span>
        </span></li>
        <li>Cleaned Word <span class="tooltip">❓
            <span class="tooltiptext">Compares text similarity using cleaned tokens. Cosine Similarity is used, with tokens undergoing stop word removal, punctuation removal, and lemmatization.</span>
        </span></li>
        <li>Uncleaned Word <span class="tooltip">❓
            <span class="tooltiptext">Compares text similarity using raw, unprocessed tokens without cleaning. Cosine Similarity is used to measure similarity.</span>
        </span></li>
        <li>Cleaned Phrase <span class="tooltip">❓
            <span class="tooltiptext">Compares noun phrases extracted from cleaned tokens. Tokens are processed to remove stop words, punctuation, and undergo lemmatization. Cosine Similarity is used for comparison.</span>
        </span></li>
        <li>Uncleaned Phrase <span class="tooltip">❓
            <span class="tooltiptext">Compares noun phrases extracted from raw, unprocessed tokens using POS tagging and chunking. Cosine Similarity is used for comparison.</span>
        </span></li>
        <li>Spelling <span class="tooltip">❓
            <span class="tooltiptext">Detects spelling similarities using Jaccard Similarity, calculating the overlap of unique words between two texts. Preprocessing includes stop word removal but excludes lemmatization.</span>
        </span></li>
        <li>Embedding <span class="tooltip">❓
            <span class="tooltiptext">Compares semantic similarity using embeddings generated by a Sentence Transformer model. Cleaned text is encoded into vector representations, and Cosine Similarity is used for comparison.</span>
        </span></li>
    </ul>
</div>
""", unsafe_allow_html=True)


# Sidebar options
data_path = st.sidebar.text_input("Enter directory path for PDF files:")
comparison_type = st.sidebar.selectbox(
    "Choose comparison type:",
    ["Fast Checking", "All Checking"]
)

if comparison_type == "All Checking":
    # Display description about method selection
    st.sidebar.warning(
        "⚠️ For large folders, avoid selecting more than 3 methods, as it may significantly increase the runtime."
    )
    methods = st.sidebar.multiselect(
        "Select methods for comparison:",
        [
            "Cleaned Word", "Uncleaned Word", "Cleaned Phrase", "Uncleaned Phrase",
            "Spelling", "Embedding", "Individual Image", "Concatenated Image"
        ]
    )
    
elif comparison_type == "Fast Checking":
    methods = ["Cleaned Word", "Concatenated Image"]

# Ensure session state for thresholds and results
if "results" not in st.session_state:
    st.session_state["results"] = None

if "thresholds" not in st.session_state:
    st.session_state["thresholds"] = {}

# Initialize thresholds for selected methods dynamically
for method in methods:
    if method not in st.session_state["thresholds"]:
        st.session_state["thresholds"][method] = 0.5  # Default threshold

# Run analysis button
if st.button("Run Analysis"):
    if not data_path:
        st.error("Please enter a valid directory path.")
    else:
        st.info("Processing PDFs...")
        # Start the timer
        start_time = time.time()
        pdf_data =  extract_pdfs_into_list(data_path)
        if len(pdf_data) < 2:
            st.error("Need at least two PDF files for comparison.")
        else:
            st.success(f"Loaded {len(pdf_data)} PDF files.")

            

            results = []
            for i, pdf1 in enumerate(pdf_data[:-1]):
                for pdf2 in pdf_data[i+1:]:
                    comparisons = {}

                    # Text-based comparisons
                    if "Cleaned Word" in methods:
                        comparisons["Cleaned Word"] = text_processor.cosine_similarity_cleaned(
                            pdf1['text'], pdf2['text']
                        )
                    if "Uncleaned Word" in methods:
                        comparisons["Uncleaned Word"] = text_processor.cosine_similarity_uncleaned(
                            pdf1['text'], pdf2['text']
                        )
                    if "Cleaned Phrase" in methods:
                        comparisons["Cleaned Phrase"] = text_processor.cosine_similarity_phrases_cleaned(
                            pdf1['text'], pdf2['text']
                        )
                    if "Uncleaned Phrase" in methods:
                        comparisons["Uncleaned Phrase"] = text_processor.cosine_similarity_uncleaned(
                            pdf1['text'], pdf2['text']
                        )
                    if "Spelling" in methods:
                        comparisons["Spelling"] = text_processor.jaccard_similarity_for_spelling(
                            pdf1['text'], pdf2['text']
                        )
                    if "Embedding" in methods:
                        comparisons["Embedding"] = text_processor.compute_embedding_similarity(
                            pdf1['text'], pdf2['text']
                        )

                    # Individual Image comparison
                    if "Individual Image" in methods:
                        comparisons["Individual Image"] = image_processor.threaded_pdf_comparison(
                            pdf1['image'], pdf2['image']
                        )

                   # Concatenated Image comparison
                    if "Concatenated Image" in methods:
                        # Use pre-extracted color images for concatenated image comparison
                        comparisons["Concatenated Image"] = image_processor_concatenated.compare_pdfs_concatenated(
                            pdf1['image_color'], pdf2['image_color']
                        )
                        print(f"Concatenated Image Similarity between {pdf1['path']} and {pdf2['path']}: {comparisons['Concatenated Image']}")

                    # Append results
                    results.append({
                        "File 1": pdf1["path"],
                        "File 2": pdf2["path"],
                        **comparisons
                    })

            

            # Store results in session state
            st.session_state["results"] = pd.DataFrame(results)

            # End the timer
            end_time = time.time()
            # Calculate elapsed time
            elapsed_time = end_time - start_time
            formatted_time = format_time(elapsed_time)
            
            # Display success message with formatted time taken
            st.success(f"Analysis complete! Time taken: {formatted_time}.")

# Display results and graphs for each method
if st.session_state["results"] is not None:
    results_df = st.session_state["results"]
    print("Results DataFrame Preview:")
    print(results_df.head())
    for method in methods:
        if method in results_df.columns:
            # Separate result box and graph for each method
            st.subheader(f"Results for {method}")
            
            # Add threshold slider for this method
            threshold = st.slider(
                f"Set threshold for {method}",
                0.0, 1.0, st.session_state["thresholds"][method], step=0.01,
                key=f"{method}_threshold_slider"
            )

            # Filter results based on the threshold
            filtered_results = results_df[results_df[method] > threshold]

            # Display filtered results
            st.write(f"Filtered Results for {method} (Threshold: {threshold}):")
            st.dataframe(filtered_results)

            # Plot distribution for this method
            st.write(f"Similarity Distribution for {method}:")
            scores = results_df[method].dropna()
            fig, ax = plt.subplots()
            sns.histplot(scores, kde=True, bins=10, ax=ax)
            ax.axvline(x=threshold, color='r', linestyle='--', label=f'Threshold ({threshold})')
            ax.set_title(f"{method} Similarity Distribution")
            ax.set_xlabel("Similarity Score")
            ax.set_ylabel("Frequency")
            ax.legend()
            st.pyplot(fig)

if __name__ == "__main__":
    directory = r"C:\Users\Benson\Documents\plagiarism_checker_final\sample_pdfs"
    pdf_data = extract_pdfs_into_list(directory)

    texts = [pdf["text"] for pdf in pdf_data]

    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(texts)

    similarity = cosine_similarity(tfidf_matrix)

    print("Similarity matrix:")
    print(similarity)
